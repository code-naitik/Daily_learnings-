GitHub Copilot is an AI-powered coding assistant. It helps you write code faster and with fewer errors by suggesting:

 Code completions – It predicts the next few lines or even whole functions as you type.
 Code snippets – It suggests common patterns or boilerplate code for various tasks.
 Function or comment completion – Write a comment describing what you want, and Copilot tries to generate the corresponding code.
 Learning new APIs – It suggests how to use libraries or frameworks you might not know well.

It works directly in code editors like Visual Studio Code, Visual Studio, Neovim, and some JetBrains IDEs.

GitHub Copilot is powered by OpenAI’s models (originally Codex, now more advanced versions). It’s trained on a huge dataset of publicly available code and natural language.


Using GitHub Copilot with JavaScript:
GitHub copilot suggests code completions, entire functions, and even complex logic based on comments or partially written code. Integrated into editors like Visual Studio Code, Copilot analyzes the context of your JavaScript files and offers intelligent suggestions, saving time on boilerplate code and helping discover new patterns or APIs. However, it’s important to review Copilot’s suggestions carefully to ensure correctness and security in your code.
Complete a function from a comment

You type:

// Function to check if a number is prime
function isPrime(n) {
Copilot might suggest:

    if (n <= 1) return false;
    for (let i = 2; i <= Math.sqrt(n); i++) {
        if (n % i === 0) return false;
    }
    return true;
}


What is prompt engineering?
Prompt engineering is the process of crafting clear instructions to guide AI systems, like GitHub Copilot, to generate context-appropriate code tailored to your project's specific needs. This ensures the code is syntactically, functionally, and contextually correct.

Best practices in prompt engineering:
The following advanced practices, based on the 4 Ss, refine and enhance your engagement with Copilot, ensuring that the generated code isn't only accurate but perfectly aligned with your project's specific needs and contexts.


Principles of prompt engineering:
Before we explore specific strategies, let's first understand the basic principles of prompt engineering, summed up in the 4 Ss below. These core rules are the basis for creating effective prompts.

Single: Always focus your prompt on a single, well-defined task or question. This clarity is crucial for eliciting accurate and useful responses from Copilot.
Specific: Ensure that your instructions are explicit and detailed. Specificity leads to more applicable and precise code suggestions.
Short: While being specific, keep prompts concise and to the point. This balance ensures clarity without overloading Copilot or complicating the interaction.
Surround: Utilize descriptive filenames and keep related files open. This provides Copilot with rich context, leading to more tailored code suggestions.

Assert and iterate:-
One of the keys to unlocking GitHub Copilot's full potential is the practice of iteration. Your first prompt might not always yield the perfect code, and that's perfectly okay. If the first output isn't quite what you're looking for, treat it as a step in a dialogue. Erase the suggested code, enrich your initial comment with added details and examples, and prompt Copilot again.

Zero-shot learning:
Here, GitHub Copilot generates code without any specific examples, relying solely on its foundational training. For instance, suppose you want to create a function to convert temperatures between Celsius and Fahrenheit. You can start by only writing a comment describing what you want, and Copilot might be able to generate the code for you, based on its previous training, without any other examples.
Zero-shot learning means a machine can recognize things it has never seen before, just by understanding descriptions or relationships.

Example:

Suppose you train an AI to recognize cats, dogs, and horses.

Now you ask it to recognize a zebra, but it has never seen zebra photos.

You tell it: “A zebra looks like a horse but has black-and-white stripes.”

The AI uses what it knows about horses and the idea of “black-and-white stripes” to figure out what a zebra might look like.

So, zero-shot learning = recognizing new things without direct training examples, using descriptions or connections to known things.

One-shot learning:-
With this approach, a single example is given, aiding the model in generating a more context-aware response. Building upon the previous zero-shot example, you might provide an example of a temperature conversion function and then ask Copilot to create another similar function. Here's how it could look.
 One-shot learning means a machine learns to recognize something after seeing only one example of it.

Example:

You show the AI one photo of your friend’s face.

Next time it sees your friend, even in a different photo, it recognizes them.

Humans do this easily—see something once and remember it. For machines, it’s much harder, because they usually need lots of examples to learn well.

So, one-shot learning = learning from just one example.

Few-shot learning means a machine learns something new from only a few examples — like 2, 5, or 10 pictures instead of thousands.

Example:

You show the AI 5 photos of a panda.

After those few photos, it can recognize pandas in new images.

So, compared to:

Zero-shot learning → no examples, only descriptions.

One-shot learning → one example.

Few-shot learning → a few examples.

Few-shot learning = learning from just a small number of examples.

Inbound data flow:

Inbound data flow means data coming into a system from outside sources.

Example:

A website collects user sign-up info → that’s inbound data flow.

A company gets orders from customers → inbound data flow.

Sensors send temperature readings to a server → inbound data flow.

So, inbound = data coming in.

Secure prompt transmission and context gathering:-
The process begins with the secure transmission of the user prompt over HTTPS. This ensures that your natural language comment is sent to GitHub Copilot's servers securely and confidentially, protecting sensitive information.

Proxy filter:-
Once the context is gathered and the prompt is built, it passes securely to a proxy server hosted in a GitHub-owned Microsoft Azure tenant. The proxy filters traffic, blocking attempts to hack the prompt or manipulate the system into revealing details about how the model generates code suggestions.

Toxicity filtering:-
Copilot incorporates content filtering mechanisms before proceeding with intent extraction and code generation, to ensure that the generated code and responses don't include or promote:

Hate speech and inappropriate content: Copilot employs algorithms to detect and prevent the intake of hate speech, offensive language, or inappropriate content that could be harmful or offensive.
Personal data: Copilot actively filters out any personal data, such as names, addresses, or identification numbers, to protect user privacy and data security.

Code generation with LLM:-
Finally, the filtered and analyzed prompt is passed to LLM Models, which generate appropriate code suggestions. These suggestions are based on Copilot’s understanding of the prompt and the surrounding context, ensuring that the generated code is relevant, functional, and aligned with project-specific requirements.

Using GitHub Copilot with Python
GitHub Copilot is a groundbreaking AI developer tool designed to accelerate your coding workflow by offering intelligent, autocomplete-style suggestions as you write. In this module, you’ll harness the power of GitHub Copilot to enhance your Python coding efficiency.
Add a Pydantic model
Go to the main.py file, navigate to the bottom of the provided code, select Ctrl + I (PC) or Cmd + I (Mac) and copy the following into the provided GitHub Copilot Chat box so that it can generate a Pydantic model for you:

Create a Pydantic model so that I can use it in a new route that will accept JSON with text as a key which accepts a string.






                                                                          Artificial Intelligence for beginners 
                                                                          
                                                                          
 Neural network and deep learning are the core of modern AI: Neural architecture is used for work with image and text.
 

 Weak AI (Narrow AI)
 Definition:

AI systems designed and trained for a specific task.

They do not possess consciousness, genuine understanding, or self-awareness.

 Key Features:

Perform limited, narrow functions.

Operate within predefined parameters.

Cannot truly understand meaning or context the way humans do.

 Examples:

Siri, Alexa, or Google Assistant

Chatbots

Image recognition software

Spam filters

Recommendation systems (Netflix, YouTube, Amazon)

 Alternate Names:

Narrow AI

Applied AI

Strong AI (Artificial General Intelligence – AGI)
 Definition:

AI with human-level (or beyond) cognitive abilities.

Capable of understanding, reasoning, and learning across any domain, just like a human.

 Key Features:

Consciousness or awareness (theoretical)

Understands context and meaning

Can solve problems it wasn’t explicitly programmed for

Has flexible, general intelligence

 Examples:

None exist yet. Strong AI is still theoretical.

 Alternate Names:

Artificial General Intelligence (AGI)

Full AI

Human-level AI

Turing test:- The Turing Test is a method proposed by Alan Turing in 1950 to answer the question:

“Can machines think?”

Instead of directly defining “thinking,” Turing suggested a practical test.

How the Turing Test Works
Imagine a human judge chatting (usually via text) with:

A human, and

A machine (computer program or AI)

The conversations happen blindly:

The judge doesn’t know who’s human and who’s the machine.

The judge asks any questions they want.

 The machine passes the Turing Test if:

The judge cannot reliably tell the machine apart from the human based on the conversation.


             Turing Test in simple words = A game to see if you can tell a human from a machine by chatting with them.
             
             
     Top-Down Approach(Symbolic reasoning)
Definition:

Start from the big picture or overall system.

Break it down into smaller parts or detailed steps.

How it works:

Understand the whole system or goal.

Divide it into major components.

Keep breaking each part into smaller tasks until you reach the simplest level.

Advantages:

Clear vision of the overall goal.

Good for planning large systems.

Helps keep work organized.

Examples:

Designing software by first planning overall architecture, then coding individual modules.

Writing an essay by outlining main sections first, then filling in details.

Management planning company goals first, then assigning tasks to departments.

   Bottom-Up Approach(Neural Network)
Definition:

Start with small, simple parts.

Combine them to build more complex systems.

How it works:

Create or analyze small, basic units.

Integrate them to form bigger structures.

Keep combining until you achieve the full system.

Advantages:

Often leads to reusable, flexible components.

Good for exploring unknown problems.

Encourages innovation in small parts.

Examples:

Writing small functions first, then combining them into a program.

Learning letters and sounds before forming words and sentences.

Scientists studying atoms and molecules to understand larger materials.

Machine learning:- Part of Artificial Intelligence that is based on computer learning to solve a problem based on some data is called Machine Learning. 

Computer knowledge representation:-
Network representations are based on the fact that we have a network of interrelated concepts inside our head. We can try to reproduce the same networks as a graph inside a computer - a so-called semantic network. In simple words a semantic network is a way of representing knowledge using a graph of nodes and links:

Nodes → represent concepts, objects, ideas, or words (e.g. Cat, Animal, Has Fur).
Links (edges) → represent relationships between those concepts (e.g. is-a, has, part-of).

1.Object-Attribute-Value triplets or attribute-value pairs:- Since a graph can be represented inside a computer as a list of nodes and edges, we can represent a semantic network by a list of triplets, containing objects, attributes, and values. For example, ollowing triplets about programming languages:


_______________________________________________________________________________
|Object	         |      Attribute	   |                   Value                |
|Python	         |        is         |               Untyped-Language         |
|Python	         |   invented-by     |         	    Guido van Rossum          |
|Python	         |   block-syntax    |               	indentation             |
|Untyped-Language|	 doesn't have	   |               type definitions         |
_______________________________________________________________________________

2.Hierarchical representations are ways of organizing information in a tree-like structure, where elements are arranged at different levels of importance, generality, or specificity.

Key ideas:

Levels of hierarchy — concepts at the top are broader or more general, while those lower down are more specific.

 Parent-child relationships — higher-level concepts act as “parents,” and lower-level concepts are their “childrenff

 Single path upward — each item (except the topmost) has one direct parent.
For ex.


            Animal
          /        \
       Mammal      Bird
      /      \         \
    Dog      Cat      Sparrow

Animal is the most general concept.

Mammal and Bird are subcategories.

Dog, Cat, and Sparrow are specific examples.


A frame representation is a way of storing knowledge using data structures called frames. Each frame represents a concept, object, situation, or event, and contains slots that hold information about its attributes and relationships.
Scenarios are special kind of frames that represent complex situations that can unfold in time.

Frame: Car
-------------------------
Type         : Vehicle
Color        : Red
Wheels       : 4
Engine-Type  : Petrol
Owner        : John

+----------------+---------------------+----------------+------------------+
| Slot           | Value               | Default value  | Interval         |
+----------------+---------------------+----------------+------------------+
| Name           | Python              |                |                  |
| Is-A           | Untyped-Language    |                |                  |
| Variable Case  |                     | CamelCase      |                  |
| Program Length |                     |                | 5-5000 lines     |
| Block Syntax   | Indent              |                |                  |
+----------------+---------------------+----------------+------------------+

3.Procedural representations are based on representing knowledge by a list of actions that can be executed when a certain condition occurs.

Production rules are if-then statements that allow us to draw conclusions. For example, a doctor can have a rule saying that IF a patient has high fever OR high level of C-reactive protein in blood test THEN he has an inflammation. Once we encounter one of the conditions, we can make a conclusion about inflammation, and then use it in further reasoning.
Algorithms can be considered another form of procedural representation, although they are almost never used directly in knowledge-based systems.
Predicate Logic (also called First-Order Logic) is a way to represent knowledge using predicates, variables, and quantifiers. It’s more powerful than simple true/false statements because it can describe relationships and properties of objects.


Basic Components
Predicate → expresses a property or a relationship.

Example:

Tall(John) → “John is tall.”

Loves(Alice, Bob) → “Alice loves Bob.”

 Variables → stand for objects.

Example: x, y, z

 Constants → specific objects.

Example: John, Bob

 Quantifiers → state how many things satisfy a condition:

Universal quantifier ( ∀ ) → “for all”

∀x Tall(x) → “Everyone is tall.”

Existential quantifier ( ∃ ) → “there exists”

∃x Tall(x) → “Someone is tall.”

4.Logic was originally proposed by Aristotle as a way to represent universal human knowledge.

Predicate Logic as a mathematical theory is too rich to be computable, therefore some subset of it is normally used, such as Horn clauses used in Prolog.
Descriptive Logic is a family of logical systems used to represent and reason about hierarchies of objects distributed knowledge representations such as semantic web.
Description Logic (DL) is a family of formal logics used to represent structured knowledge and reason about it. It's widely used in semantic web, ontology design, and knowledge-based systems.

What is an Expert System?
An expert system is a type of Artificial Intelligence (AI) program that mimics the decision-making ability of a human expert.
It uses:

Rules

Facts

Reasoning techniques

to solve problems that usually require human expertise.

How does it work?
An expert system has two main parts:

Part	               |                  What it does
Knowledge Base	     |       Stores facts and rules from human experts.
Inference Engine	   |       Applies rules to facts to draw conclusions.


Forward vs. Backward Inference:
Forward inference is a reasoning method that:

 Starts with known facts
 Applies rules to those facts
Generates new facts or conclusions

→ It’s data-driven reasoning.
How does it work?
Look at all known facts.

Check which rules can “fire” (i.e. whose conditions are satisfied).

Apply those rules to produce new facts.

Repeat the process until:

No more rules apply, OR

A goal is reached.
Rule 1: IF sky_is_cloudy THEN it_might_rain
Rule 2: IF it_might_rain THEN carry_umbrella

Backward inference is a reasoning method that:

 Starts with a goal or question
 Works backward through rules
 Tries to prove the goal using known facts

→ It’s goal-driven reasoning.

How does it work?
Start with what you want to prove (the goal).

Look for rules whose conclusions match the goal.

For each rule, check whether its conditions are true:

If conditions are facts → goal proven!

If not → treat conditions as new sub-goals and try to prove them.

Repeat until:

The goal is proven, OR

It’s impossible to prove.

Rule 1: IF sky_is_cloudy THEN it_might_rain
Rule 2: IF it_might_rain THEN carry_umbrella


Ontologies and the Semantic Web:
The Semantic Web is an extension of the current web that aims to make data understandable to machines, not just humans.

Instead of web pages being just text or images for people to read, the Semantic Web adds meaning (semantics) to the data so computers can process, connect, and reason about information intelligently.

In short:

Semantic Web = Web of data with meaning.
Example:

A page says “Paris” — is it the city, a person’s name, or a brand?

The Semantic Web helps clarify:

Paris → rdf:type City

Paris → locatedIn France



Ontology defines:

Classes: Animal, Mammal, Bird, Dog, Cat

Properties: hasLegs, eats, livesIn

Relationships:

Dog is-a Mammal

Dog hasLegs 4

Dog eats Meat

Neural Network:
A Neural Network is an AI technique inspired by how the human brain works.

In simple words:

A neural network is a system that learns from data, understands patterns, and makes predictions or decisions.

Inspired by the Human Brain
The human brain has billions of neurons connected to each other.

Similarly, a neural network has artificial neurons (also called nodes) connected in layers.

Machine Learning:
Neural Networks are a part of a larger discipline called Machine Learning, whose goal is to use data to train computer models that are able to solve problems. Machine Learning constitutes a large part of Artificial Intelligence. 

What is a Perceptron?
A Perceptron is the simplest type of artificial neural network unit (a single “neuron”). A perceptron is a binary classification model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class. The output will be computed using the formula:

y(x) = f(wTx)
To train a perceptron we need to find a weights vector w that classifies most of the values correctly, i.e. results in the smallest error. This error E is defined by perceptron criterion in the following manner:

E(w) = -∑wTxiti
where:

the sum is taken on those training data points i that result in the wrong classification
xi is the input data, and ti is either -1 or +1 for negative and positive examples accordingly.
This criteria is considered as a function of weights w, and we need to minimize it. Often, a method called gradient descent is used, in which we start with some initial weights w(0), and then at each step update the weights according to the formula:

w(t+1) = w(t) - η∇E(w)

Here η is the so-called learning rate, and ∇E(w) denotes the gradient of E. After we calculate the gradient, we end up with

w(t+1) = w(t) + ∑ηxiti


A simple network contained one neuron, also called a threshold logic unit. 

In simple words:

A perceptron takes some numbers as input, does some math, and decides yes or no as output.

 What are Multi-Layered Networks?
A Multi-Layered Network is a type of neural network that has more than one layer of neurons between the input and the output.

In simple words:

It’s a neural network with multiple layers that helps it learn complex patterns in data.

What is a Neural Network Framework?
A Neural Network Framework is a software library or tool that makes it easier for developers and researchers to build, train, and deploy neural networks.

In simple words:

A neural network framework is like a toolbox full of ready-made tools and shortcuts to help you create AI models without writing everything from scratch.

Overfitting happens when a machine learning or neural network model learns too much detail from the training data — including noise or random patterns that don’t really matter.

In simple words:

Overfitting is when your model memorizes the training data instead of understanding the real pattern.

Perceptron ek simple artificial neuron hota hai jo machine learning aur neural networks mein use hota hai. Matlab, yeh ek mathematical model hai jo dimaag ke neuron jaise kaam karta hai.

Kaise kaam karta hai:

Inputs – Perceptron kuch numbers (inputs) leta hai. Jaise x1, x2,....

Weights se multiply – Har input ko ek number (weight) se multiply karta hai.

Sab add karo – In multiplied values ko add kar deta hai.

Bias add hota hai – Is total mein ek extra number (bias) add hota hai. Bias help karta hai decision boundary ko adjust karne mein.

Activation Function – Total value check karta hai. Agar total 0 se bada hai, output 1 deta hai, warna 0. Matlab ON ya OFF decide karta hai.

         {1 agr ∑(Wi . Xi)+b >0
output = {
​         {0 warna

Xi = inputs
Wi = weights
b = bias


 
Example
Maan lo:

Inputs: x1 = 2, x2 = 3

Weights: w1 =0.5, w2 = -1

Bias: 
𝑏=1

Calculation:  (2×0.5)+(3×−1)+1=1−3+1=−1

Result negative hai, toh perceptron output karega 0.

Use kya hai? – Perceptron simple decision lene mein help karta hai, jaise do classes ko separate karna (spam ya non-spam). Lekin ek single perceptron sirf simple (linearly separable) problems solve kar sakta hai. Complex kaam ke liye multiple perceptrons ko layers mein jod ke neural network bnaate h.

Bias :
Ye ek extra number hota hai jo perceptron (ya kisi bhi neuron) ke calculation mein add kiya jaata hai. Iska kaam hai decision boundary ko shift karna. Matlab, ye help karta hai ki model sirf origin (zero) ke aas-paas depend na kare, balki thoda flexible decision le sake.

Ek tareeke se samjhein:

Sochiye aap ek line draw kar rahe hain jo do cheezein alag kar rahi hai. Agar aapke paas bias nahi hoga, toh woh line hamesha origin se guzregi. Bias se aap woh line upar, neeche, ya side mein shift kar sakte hain. Isse model better kaam karta hai, kyunki real-life data perfect zero se start nahi hota.

A Multi-Layered Perceptron (MLP) is a type of artificial neural network made up of an input layer, one or more hidden layers, and an output layer, where each neuron in one layer connects to every neuron in the next. It uses activation functions and learns patterns from data through training with backpropagation.

Formalization in Machine Learning (ML) means translating a real-world problem into a precise mathematical or computational form so that it can be solved using ML algorithms.

In other words, you take an ambiguous, messy problem and express it in a way a computer can understand and work with.

A mathematical problem in machine learning is like this:

 You have numbers as input.
 You want to find a way to get the right answer (output) from those numbers.
 You measure how good or bad your guesses are.
 You improve your guesses to make them as correct as possible.

Example (Easiest)
Imagine this problem:

Predict the price of a house.

 Input (numbers you know):

Size of the house = 2000 sq. ft.

Number of bedrooms = 3

 Output (what you want to predict):

Price of the house

So the mathematical problem is:

Find a formula that uses these numbers (size, bedrooms) to guess the price.

Like this:

price : a X size + b X beddroom + c
a,b,c are numbers you need to figure out.

You adjust these numbers until your formula predicts prices close to the real prices in your data.

That’s the mathematical problem in ML.

Inputs = numbers (features)

Output = number or label (prediction)

Goal = find the best formula or model

In one line:
A mathematical problem in ML means “find a formula to turn input numbers into the right answers.”

A loss function in machine learning is a way to measure how wrong your model’s predictions are.

Think of it like a score for mistakes. Lower score = better model!


Absolute Error
Absolute error = how far off you are, ignoring the sign.
Absolute Error = |Real value − Predicted value|
Example:

Real price = $500,000

Predicted = $480,000

Absolute Error = |500,000 - 480,000| = 20,000

so you are 20,000 off

Squared Error
Squared error = error squared.

Squared Error = (real value - predicted value) X (real value - predicted value)

Example:
real value = $500,000
Predicted value = $480,000
Squared error = (500,000 - 480,000) X (500,000 - 480,000) = 400,000,000

So, the error is 400 million (but note: this is not in dollars, it’s just a number).

What is Logistic Loss?
Logistic loss (also called log loss or cross-entropy loss) measures how good or bad your predictions are for classification problems, especially when predicting probabilities.


Multi-Layered Perceptrons and Backpropagation
One-layer network, as we have seen above, is capable of classifying linearly separable classes. To build a richer model, we can combine several layers of the network. Mathematically it would mean that the function f would have a more complex form, and will be computed in several steps:

z1=w1x+b1
z2=w2α(z1)+b2
f = σ(z2)





